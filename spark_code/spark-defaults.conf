spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension
spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog
spark.sql.warehouse.dir=/opt/datasets/warehouse
spark.hadoop.fs.defaultFS=file:///

# PostgreSQL Metastore Configuration
spark.hadoop.javax.jdo.option.ConnectionURL=jdbc:postgresql://metastore-db:5432/metastore
spark.hadoop.javax.jdo.option.ConnectionDriverName=org.postgresql.Driver
spark.hadoop.javax.jdo.option.ConnectionUserName=hive
spark.hadoop.javax.jdo.option.ConnectionPassword=hive
spark.hadoop.datanucleus.autoCreateSchema=true
spark.hadoop.datanucleus.fixedDatastore=false
spark.hadoop.datanucleus.schema.autoCreateAll=true
spark.hadoop.hive.metastore.schema.verification=false
spark.hadoop.hive.metastore.schema.verification.record.version=false

# Python path
spark.executor.extraPythonPath=/opt/spark_code
spark.driver.extraPythonPath=/opt/spark_code